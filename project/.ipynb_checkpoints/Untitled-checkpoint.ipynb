{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ListedColormap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d20f690a9af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m#print(statistics.mean(acc));\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m#print(statistics.stdev(acc));\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-d20f690a9af6>\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, classifier, test_idx, resolution)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmarkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lightgreen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cyan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListedColormap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# plot the decision surface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ListedColormap' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "scaler=StandardScaler()\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Import packages to do the classifying\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        if not versiontuple(np.__version__) >= versiontuple('1.9.0'):\n",
    "            X_test, y_test = X[list(test_idx), :], y[list(test_idx)]\n",
    "            warnings.warn('Please update to NumPy 1.9.0 or newer')\n",
    "        else:\n",
    "            X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    alpha=1.0,\n",
    "                    linewidths=1,\n",
    "                    marker='o',\n",
    "                    s=55, label='test set')\n",
    "\n",
    "def PCA(data):\n",
    "    '''\n",
    "    Input: data\n",
    "    output: Eigen Value-Vector pair, variance explained by components\n",
    "    '''\n",
    "    #Calculating Eigen values and Eigen vectors \n",
    "    values,vectors=np.linalg.eig(data.cov())\n",
    "    # binding values and vector in a tuple\n",
    "    eig_pairs = [(np.abs(values[i]), vectors[:,i]) for i in range(len(values))]\n",
    "    #soring according to larger Eigen Values\n",
    "    eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "    # Variance explaied \n",
    "    var_exp = [(i / sum(values))*100 for i in sorted(values, reverse=True)]\n",
    "    variance_exp=np.cumsum(var_exp)\n",
    "    return eig_pairs,variance_exp\n",
    "\n",
    "def PCA_transform(data,eig_pairs,k):\n",
    "    '''\n",
    "    Input: data,Eigen Value-Vector pair from PCA(), # principle components to use\n",
    "    output : transformed data\n",
    "    '''\n",
    "    W=[]\n",
    "    for i in range(k):\n",
    "        W.append(eig_pairs[i][1])\n",
    "    W=np.array(W)\n",
    "    \n",
    "    return np.dot(data,W.T)\n",
    "\n",
    "data = pd.read_csv('avila-tr.txt', sep=\",\", header=None)\n",
    "num_samples=data.shape[0]\n",
    "\n",
    "x = data.iloc[:,0:10];\n",
    "y = data.iloc[:,-1];\n",
    "\n",
    "acc = [];\n",
    "\n",
    "knn = KNeighborsClassifier;\n",
    "\n",
    "#for i in range(10):\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "#scaling\n",
    "scaler.fit(x_train)\n",
    "train_df_sc =pd.DataFrame(scaler.transform(x_train),index=x_train.index , columns=x_train.columns)\n",
    "test_df_sc = pd.DataFrame(scaler.transform(x_test),index=x_test.index , columns=x_test.columns)\n",
    "#train_df_sc has 9 columns\n",
    "\n",
    "#PCA\n",
    "eig_pairs,variance_exp = PCA(train_df_sc)\n",
    "\n",
    "#PCA transformation\n",
    "transformed_train =PCA_transform(train_df_sc,eig_pairs,8)\n",
    "transformed_test =PCA_transform(test_df_sc,eig_pairs,8)\n",
    "\n",
    "clf = SVC(kernel='rbf',gamma=\"auto\")\n",
    "clf.fit(transformed_train, y_train)\n",
    "#     knnclass = knn(n_neighbors=5)\n",
    "#     knnclass.fit(transformed_train,y_train)\n",
    "#acc.append(knnclass.score(transformed_test,y_test));\n",
    "#acc.append(clf.score(transformed_test,y_test));\n",
    "    \n",
    "#print(transformed_train[0])\n",
    "\n",
    "\n",
    "#     MLE =  GaussianNB();\n",
    "#     MLE.fit(transformed_train,y_train);\n",
    "#     acc.append(MLE.score(transformed_test,y_test));\n",
    "#print(statistics.mean(acc));\n",
    "#print(statistics.stdev(acc));\n",
    "plot_decision_regions(transformed_train, y_train, classifier=clf)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#print(clf.predict(transformed_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
