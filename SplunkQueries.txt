There can be multiple hosts, and each host can have multiple Sources--
for example in a local host there is a single host machine which have many source log files.


-- The source type in data summary of an event tells you what kind of data it is, usually based on how the data is formatted. This classification lets you search for the same type of data across multiple sources and hosts.

__________________________________________________
Search Queries --
__________________________________________________

* earliest= -24h@h latest= -12h@h


- refers to the past records,
24h is the last 24 hours
earliest is keyword
@h specifies records down to the hours instead to the seconds or minutes


similarly

* earliest= -2400m@h latest= -1m@m

m - minutes and granularity of hour

__________________________________________________
process = sudo

will comeup with all sudo commands logged.

__________________________________________________

eventtype= "unix_authentication" AND by vagrant

eventtype can be any events like nix_config, kernel etc.

*****AND Keyword is always optional ******

eventtype= "unix_authentication" by vagrant will also produce same results


(eventtype=nix_configs by apt) OR shutdown AND (earliest= -500h AND latest= -1h)
__________________________________________________

************Pipe operators*************************

--> * | top user
or * | top user by host


*  host!="india-Lenovo-ideapad-330-15IKB" | top  user by host

same as 

* NOT host = "india" | top user by host

--> pwd - present working directory log

____________________________________________________
**********Regular expression queries*****************

PWD |rex "PWD=(?<pwd>[^;]+)"

rex-- regular expression 
pwd = find following files in present directory


When you add data to the Splunk platform the data is indexed. As part of the  index process, information is extracted from your data and formatted as name and value pairs, called fields. When you run a search, the fields are identified and listed in the Fields sidebar next to your search results. The fields are divided into two categories.

Selected fields are visible in your search results. By default, host, source, and sourcetype appear. You can select other fields to show in your events.
Interesting fields are other fields that have been extracted from the events in your search results. 

____________________________________________________Fields and indexing___________________________

Field - key, value pair

Extracted fields

The Splunk software extracts fields from event data at index time and at search time.

***Index time

The time span from when the Splunk software receives new data to when the data is written to an index. During index time, the data is parsed into segments and events. Default fields and timestamps are extracted, and transforms are applied.

*** Search time

The period of time beginning when a search is launched and ending when the search finishes. During search time, certain types of event processing take place, such as search time field extraction, field aliasing, source type renaming, event type matching, and so on.

The default fields and other indexed fields are extracted for each event when your data is indexed.

When you first run a search the Selected Fields list contains the default fields host, source, and sourcetype. These default fields appear in every event.

Interesting Fields are fields that appear in at least 20% of the events.


example - 
	-- sourcetype=access_* status=200 action=purchase
	-- sourcetype=access_* status=200 action=purchase

____________________________________________________________________________________________________

PIPE ( | )


After action=purchase, type a pipe character ( | ) into the Search bar.
The pipe character indicates that you are about to use a command. The results of the search to the left of the pipe are used as the input to the command to the right of the pipe. You can pass the results of one command into another command in a series, or pipeline, of search commands.

____________________________________________________________________________________________________

Sample Reports --

Reports are like saved searches over the time...

Error report Query -> error OR failed OR severe OR ( sourcetype=access_* ( 404 OR 500 OR 503 ) )

TimeChart

source="/var/log/*" host="india-Lenovo-ideapad-330-15IKB" | timechart count

we pipe the data to the timechart by counting the data occurance at that time...



Alert----

add alert on a specific condition, report will always be saved but alerts will be made or saved only when the alert condition is met.


____________________________________________________________________________________________________
____________________________________________________________________________________________________
____________________________________________________________________________________________________
___________________________________ Forwarder  universal____________________________________________
____________________________________________________________________________________________________
____________________________________________________________________________________________________
____________________________________________________________________________________________________

The universal forwarder

About the universal forwarder

The universal forwarder collects data from a data source or another forwarder and sends it to a forwarder or a Splunk deployment. With a universal forwarder, you can send data to Splunk Enterprise, Splunk Light, or Splunk Cloud. It also replaces the Splunk Enterprise light forwarder. The universal forwarder is available as a separate installation package.

The universal forwarder offers advantages over using a heavy or light forwarder. The most notable benefit is that it uses significantly fewer hardware resources than other Splunk software products. It can, for example, coexist on a host that runs a Splunk Enterprise instance. It also is more scalable than the other Splunk products, as you can install thousands of universal forwarders with little impact on network and host performance.

Another benefit is its availability for installation on many diverse computing platforms and architectures. You can install it on more platforms than you can Splunk Enterprise.

The universal forwarder includes only the essential components that it needs to forward data to other Splunk platform instances. While it does not have a Web interface, you can still configure, manage, and scale it by editing configuration files or by using the Forwarder Management or Monitoring Console interfaces in Splunk Web.

--> download forwarder
--> opt/splunkforwarder/bin ./splunk start --accept-license

--> ./splunk enable boot-start

Forward log to central server by  

-->  opt/splunkforwarder/bin  ./splunk add forwarder 192.168.1.161:1997

and also allow splunk to monitor all the files (which files to forward to)..so here we specify the files that need to be monitored by forwarder

--> ./splunk add monitor /var/log/

--> can also specify additional properties like - 

./splunk add monitor /var/log/ -index main -sourcetype MyUniversalLogForwarder

will index this data in main index and name the source type as MyUniversalLogForwarder

______________________________________________________________________________________________

finally make sure that the port at the recieving end i.e. splunk is open for data-

----->  ./splunk enable listen 9997

